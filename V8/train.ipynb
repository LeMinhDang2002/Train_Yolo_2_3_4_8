{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "\n",
    "# ----------------- Torch Components -----------------\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# ----------------- Extra Components -----------------\n",
    "from utils import distributed_utils\n",
    "from utils.misc import compute_flops\n",
    "\n",
    "# ----------------- Config Components -----------------\n",
    "from config import build_dataset_config, build_model_config, build_trans_config\n",
    "\n",
    "# ----------------- Model Components -----------------\n",
    "from models.detectors import build_model\n",
    "\n",
    "# ----------------- Train Components -----------------\n",
    "from engine import build_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.seed = 42\n",
    "        self.cuda = False\n",
    "\n",
    "        self.img_size = 640\n",
    "        self.eval_first = False\n",
    "\n",
    "        self.tfboard = False\n",
    "        self.save_folder = 'weights/'\n",
    "        self.vis_tgt = False\n",
    "        self.vis_aux_loss = False\n",
    "        self.fp16 = False\n",
    "        self.batch_size = 16\n",
    "\n",
    "        self.max_epoch = 150\n",
    "        self.wp_epoch = 1\n",
    "        self.eval_epoch = 10\n",
    "        self.no_aug_epoch = 20\n",
    "\n",
    "        self.model = 'yolov8_n'\n",
    "        self.conf_thresh = 0.001\n",
    "        self.nms_thresh = 0.7\n",
    "        self.topk = 1000\n",
    "        self.pretrained = None\n",
    "        self.resume = None\n",
    "        self.no_multi_labels = False\n",
    "        self.nms_class_agnostic = False\n",
    "\n",
    "        self.root = 'D:\\\\Number Plate Region\\\\Demo'\n",
    "        self.dataset = 'character'\n",
    "        self.load_cache = False\n",
    "        self.num_workers = 1\n",
    "        \n",
    "        self.multi_scale = False\n",
    "        self.ema = False\n",
    "        self.min_box_size = 8.0\n",
    "        self.mosaic = None\n",
    "        self.mixup = None\n",
    "        self.grad_accumulate = 1\n",
    "\n",
    "        self.distributed = False\n",
    "        self.dist_url = \"\"\n",
    "        self.world_size = 1\n",
    "        self.sybn = False\n",
    "        self.find_unused_parameters = False\n",
    "        self.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "print(\"Setting Arguments.. : \", args)\n",
    "local_rank = local_process_rank = -1\n",
    "if args.distributed:\n",
    "    distributed_utils.init_distributed_mode(args)\n",
    "    print(\"git:\\n  {}\\n\".format(distributed_utils.get_sha()))\n",
    "    try:\n",
    "        # Multiple Mechine & Multiple GPUs (world size > 8)\n",
    "        local_rank = torch.distributed.get_rank()\n",
    "        local_process_rank = int(os.getenv('LOCAL_PROCESS_RANK', '0'))\n",
    "    except:\n",
    "        # Single Mechine & Multiple GPUs (world size <= 8)\n",
    "        local_rank = local_process_rank = torch.distributed.get_rank()\n",
    "world_size = distributed_utils.get_world_size()\n",
    "print(\"LOCAL RANK: \", local_rank)\n",
    "print(\"LOCAL_PROCESS_RANL: \", local_process_rank)\n",
    "print('WORLD SIZE: {}'.format(world_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda and torch.cuda.is_available():\n",
    "    print('use cuda')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random_seed(args):\n",
    "    seed = args.seed + distributed_utils.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "fix_random_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = build_dataset_config(args)\n",
    "model_cfg = build_model_config(args)\n",
    "trans_cfg = build_trans_config(model_cfg['trans_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion = build_model(args, model_cfg, device, data_cfg['num_classes'], True)\n",
    "model = model.to(device).train()\n",
    "model_without_ddp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    model = DDP(model, device_ids=[args.gpu], find_unused_parameters=args.find_unused_parameters)\n",
    "    if args.sybn:\n",
    "        print('use SyncBatchNorm ...')\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model_without_ddp = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calcute Params & GFLOPs\n",
    "if distributed_utils.is_main_process:\n",
    "    model_copy = deepcopy(model_without_ddp)\n",
    "    model_copy.trainable = False\n",
    "    model_copy.eval()\n",
    "    compute_flops(model=model_copy,\n",
    "                    img_size=args.img_size,\n",
    "                    device=device)\n",
    "    del model_copy\n",
    "if args.distributed:\n",
    "    dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = build_trainer(args, \n",
    "                        data_cfg, \n",
    "                        model_cfg, \n",
    "                        trans_cfg, \n",
    "                        device, \n",
    "                        model_without_ddp, \n",
    "                        criterion, \n",
    "                        world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eval before training\n",
    "if args.eval_first and distributed_utils.is_main_process():\n",
    "    # to check whether the evaluator can work\n",
    "    model_eval = model_without_ddp\n",
    "    trainer.eval(model_eval)\n",
    "    # return\n",
    "\n",
    "## Satrt Training\n",
    "trainer.train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
